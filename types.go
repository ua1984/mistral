package mistral

import "time"

// APIError represents an error response from the Mistral API.
// It encapsulates all error information returned by the API, including HTTP status codes,
// error messages, types, and error codes. This struct implements the error interface.
type APIError struct {
	// StatusCode is the HTTP status code of the error response (e.g., 400, 401, 500).
	StatusCode int `json:"-"`

	// Message is a human-readable error message describing what went wrong.
	Message string `json:"message"`

	// Type is the category or type of error (e.g., "invalid_request_error", "authentication_error").
	Type string `json:"type,omitempty"`

	// Code is a specific error code for programmatic error handling.
	Code string `json:"code,omitempty"`
}

// Error implements the error interface for APIError.
// It returns a formatted error message that includes the error type (if available)
// followed by the error message. This allows APIError to be used wherever
// a standard Go error is expected. Returns a string in the format "type: message"
// if Type is set, otherwise just "message".
func (e *APIError) Error() string {
	if e.Type != "" {
		return e.Type + ": " + e.Message
	}
	return e.Message
}

// Role represents the role of a message sender in a chat conversation.
// Each message in a chat must have an associated role that indicates who
// or what generated the message. This is critical for the model to understand
// the context and generate appropriate responses.
type Role string

const (
	// RoleSystem represents system-level instructions that guide the model's behavior.
	// System messages typically contain instructions, context, or guidelines that
	// should influence how the model responds throughout the conversation.
	RoleSystem Role = "system"

	// RoleUser represents messages from the end user or human.
	// These are the questions, prompts, or inputs from the person
	// interacting with the AI model.
	RoleUser Role = "user"

	// RoleAssistant represents messages generated by the AI model.
	// These are the model's responses to user messages or continuations
	// of the conversation from the AI's perspective.
	RoleAssistant Role = "assistant"

	// RoleTool represents messages from tool executions.
	// When the model requests a tool/function call, the results of that
	// call are returned in a message with this role.
	RoleTool Role = "tool"
)

// ChatMessage represents a single message in a chat conversation.
// Messages form the core of interactions with the Mistral AI chat models,
// carrying content between users, the AI assistant, system instructions, and tool results.
type ChatMessage struct {
	// Role is the sender of the message (system, user, assistant, or tool).
	Role Role `json:"role"`

	// Content is the message content. Can be a string for simple text or an array of
	// content parts for multimodal messages (text, images, etc.).
	Content interface{} `json:"content"`

	// Name is an optional name of the message author, useful for distinguishing between
	// multiple users or tools in a conversation.
	Name string `json:"name,omitempty"`

	// ToolCallID is used when the role is "tool". It contains the ID of the tool call
	// that this message is responding to, linking the result back to the request.
	ToolCallID string `json:"tool_call_id,omitempty"`

	// ToolCalls contains the list of tool calls the assistant wants to make when
	// the assistant determines it needs to use tools/functions.
	ToolCalls []ToolCall `json:"tool_calls,omitempty"`
}

// ToolCall represents a tool/function call request made by the model.
// When the model determines it needs to use a tool to fulfill a request,
// it generates one or more ToolCall objects that specify which function
// to call and with what arguments.
type ToolCall struct {
	// ID is a unique identifier for this specific tool call, used to match the call
	// with its corresponding result message.
	ID string `json:"id"`

	// Type is the type of tool being called (typically "function").
	Type string `json:"type"`

	// Function contains details about the function to call, including its name and arguments.
	Function FunctionCall `json:"function"`
}

// FunctionCall represents the details of a specific function call.
// This structure contains the function name and its arguments in JSON format,
// which your application should parse and execute.
type FunctionCall struct {
	// Name is the name of the function to call, matching one of the functions
	// defined in the tools parameter of the chat completion request.
	Name string `json:"name"`

	// Arguments is a JSON-encoded string containing the arguments to pass to the function.
	// This should be parsed according to the function's parameter schema.
	Arguments string `json:"arguments"`
}

// Tool represents a tool/function that can be made available to the model.
// Tools extend the model's capabilities by allowing it to request execution of
// external functions when needed. You define the available tools upfront, and
// the model can choose to use them during generation.
type Tool struct {
	// Type is the type of tool (currently only "function" is supported).
	Type string `json:"type"`

	// Function contains the detailed specification of the function, including its name,
	// description, and parameter schema.
	Function ToolFunctionDetails `json:"function"`
}

// ToolFunctionDetails represents the complete specification of a tool function.
// This structure defines the function's interface so the model can understand
// when and how to call it.
type ToolFunctionDetails struct {
	// Name is the unique name of the function. This is what the model will reference
	// when making a function call.
	Name string `json:"name"`

	// Description is a clear description of what the function does. The model uses this
	// to determine when the function would be helpful. Be specific and detailed to
	// improve the model's decision-making.
	Description string `json:"description,omitempty"`

	// Parameters is a JSON Schema object describing the function's parameters. This should
	// follow the JSON Schema specification and define the expected structure, types,
	// and constraints for the function's input.
	Parameters map[string]interface{} `json:"parameters,omitempty"`
}

// ToolChoice represents the strategy for how the model should use the provided tools.
// This controls whether and when the model should use tool calls in its response.
type ToolChoice string

const (
	// ToolChoiceAuto lets the model automatically decide whether to use tools.
	// The model will use its judgment to determine if a tool call would be helpful
	// for answering the user's request. This is the default and most flexible option.
	ToolChoiceAuto ToolChoice = "auto"

	// ToolChoiceAny forces the model to use at least one of the provided tools.
	// The model must make at least one tool call in its response, choosing from
	// the available tools based on the context.
	ToolChoiceAny ToolChoice = "any"

	// ToolChoiceNone prevents the model from using any tools.
	// Even if tools are provided in the request, the model will not make any
	// tool calls and will respond purely with text generation.
	ToolChoiceNone ToolChoice = "none"
)

// ResponseFormat specifies the desired format for the model's response.
// This controls the structure of the generated output.
type ResponseFormat struct {
	// Type is the format type. Valid values are:
	//   - "text" - Standard text response (default)
	//   - "json_object" - Response will be valid JSON. When using this mode,
	//     you should also instruct the model to produce JSON in your prompt
	Type string `json:"type"`
}

// Usage represents token usage statistics for an API request.
// This information is essential for tracking costs and monitoring usage,
// as API pricing is typically based on token consumption.
type Usage struct {
	// PromptTokens is the number of tokens in the input prompt/messages sent to the model.
	// This includes all messages in the conversation history.
	PromptTokens int `json:"prompt_tokens"`

	// CompletionTokens is the number of tokens in the generated response/completion from the model.
	CompletionTokens int `json:"completion_tokens"`

	// TotalTokens is the sum of PromptTokens and CompletionTokens, representing
	// the total tokens used in this API request.
	TotalTokens int `json:"total_tokens"`
}

// Model represents detailed information about a Mistral AI model.
// This structure contains metadata about available models, including their
// capabilities, limitations, and ownership.
type Model struct {
	// ID is the unique identifier for the model (e.g., "mistral-large-latest", "mistral-small").
	ID string `json:"id"`

	// Object is the object type, typically "model".
	Object string `json:"object"`

	// Created is a Unix timestamp indicating when the model was created or released.
	Created int64 `json:"created"`

	// OwnedBy is the organization or entity that owns/provides the model (e.g., "mistralai").
	OwnedBy string `json:"owned_by"`

	// Type is the type or category of model (e.g., "base", "fine-tuned").
	Type string `json:"type,omitempty"`

	// Capabilities is a list of capabilities the model supports, such as "completion",
	// "chat", "embeddings", "function_calling".
	Capabilities []string `json:"capabilities,omitempty"`

	// Description is a human-readable description of the model and its characteristics.
	Description string `json:"description,omitempty"`

	// MaxTokens is the maximum number of tokens (input + output) the model can handle
	// in a single request.
	MaxTokens int `json:"max_tokens,omitempty"`
}

// ModelList represents a paginated list of models returned by the API.
// This is the response structure when listing available models.
type ModelList struct {
	// Object is the object type, typically "list".
	Object string `json:"object"`

	// Data is an array of Model objects containing details about each available model.
	Data []Model `json:"data"`
}

// DeleteModelResponse represents the API response after attempting to delete a model.
// This is returned when deleting fine-tuned models (base models cannot be deleted).
type DeleteModelResponse struct {
	// ID is the unique identifier of the model that was deleted.
	ID string `json:"id"`

	// Object is the object type, typically "model".
	Object string `json:"object"`

	// Deleted is a boolean indicating whether the deletion was successful.
	Deleted bool `json:"deleted"`
}

// EmbeddingObject represents a single embedding vector and its metadata.
// Embeddings are dense vector representations of text that capture semantic meaning,
// useful for tasks like similarity search, clustering, and classification.
type EmbeddingObject struct {
	// Object is the object type, typically "embedding".
	Object string `json:"object"`

	// Embedding is a vector of floating-point numbers representing the semantic embedding
	// of the input text. The dimensionality depends on the embedding model used.
	Embedding []float64 `json:"embedding"`

	// Index is the position of this embedding in the original input array, allowing you
	// to match results back to the corresponding input text.
	Index int `json:"index"`
}

// File represents a file that has been uploaded to the Mistral API.
// Files can be used for various purposes such as fine-tuning models or batch processing.
type File struct {
	// ID is a unique identifier for the file, used to reference it in other API calls.
	ID string `json:"id"`

	// Object is the object type, typically "file".
	Object string `json:"object"`

	// Bytes is the size of the file in bytes.
	Bytes int `json:"bytes"`

	// CreatedAt is the timestamp when the file was uploaded.
	CreatedAt time.Time `json:"created_at"`

	// Filename is the original name of the uploaded file.
	Filename string `json:"filename"`

	// Purpose is the intended purpose of the file (e.g., "fine-tune", "batch").
	// This determines how the file can be used.
	Purpose string `json:"purpose"`

	// Source contains optional information about the source or origin of the file.
	Source string `json:"source,omitempty"`
}

// FileList represents a paginated list of files returned by the API.
// This is the response structure when listing uploaded files.
type FileList struct {
	// Object is the object type, typically "list".
	Object string `json:"object"`

	// Data is an array of File objects containing details about each uploaded file.
	Data []File `json:"data"`
}

// DeleteFileResponse represents the API response after attempting to delete a file.
// This confirms whether a file was successfully removed from storage.
type DeleteFileResponse struct {
	// ID is the unique identifier of the file that was deleted.
	ID string `json:"id"`

	// Object is the object type, typically "file".
	Object string `json:"object"`

	// Deleted is a boolean indicating whether the deletion was successful.
	Deleted bool `json:"deleted"`
}

// Agent represents an AI agent configured with specific behavior and capabilities.
// Agents are persistent entities that encapsulate a model, instructions, available tools,
// and other configuration to provide consistent behavior across multiple conversations.
type Agent struct {
	// ID is a unique identifier for the agent.
	ID string `json:"id"`

	// Object is the object type, typically "agent".
	Object string `json:"object"`

	// CreatedAt is the timestamp when the agent was created.
	CreatedAt time.Time `json:"created_at"`

	// Name is a human-readable name for the agent.
	Name string `json:"name"`

	// Description is an optional description explaining the agent's purpose or capabilities.
	Description string `json:"description,omitempty"`

	// Model is the ID of the model this agent uses for generation (e.g., "mistral-large-latest").
	Model string `json:"model"`

	// Instructions are system-level instructions that guide the agent's behavior. These are
	// similar to system messages and define the agent's personality, constraints, and objectives.
	Instructions string `json:"instructions,omitempty"`

	// Tools is an array of tools/functions available to the agent for accomplishing tasks.
	Tools []Tool `json:"tools,omitempty"`

	// Metadata contains custom key-value pairs for storing additional information about the agent.
	Metadata map[string]interface{} `json:"metadata,omitempty"`
}

// Conversation represents a persistent conversation thread.
// Conversations maintain the message history and context for ongoing interactions,
// optionally associated with a specific agent.
type Conversation struct {
	// ID is a unique identifier for the conversation.
	ID string `json:"id"`

	// Object is the object type, typically "conversation".
	Object string `json:"object"`

	// CreatedAt is the timestamp when the conversation was created.
	CreatedAt time.Time `json:"created_at"`

	// Model is an optional override for the model to use in this conversation. If not set,
	// uses the agent's model (if associated with an agent) or a default model.
	Model string `json:"model,omitempty"`

	// AgentID is an optional ID of the agent associated with this conversation. If set,
	// the conversation will use the agent's instructions and tools.
	AgentID string `json:"agent_id,omitempty"`

	// Metadata contains custom key-value pairs for storing additional information about
	// the conversation.
	Metadata map[string]interface{} `json:"metadata,omitempty"`
}
